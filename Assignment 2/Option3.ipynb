{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "     ---------------------------------------- 0.0/6.8 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.6/6.8 MB 18.5 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 1.7/6.8 MB 21.3 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.4/6.8 MB 19.3 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.6/6.8 MB 21.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 4.9/6.8 MB 22.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 6.2/6.8 MB 23.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.8/6.8 MB 21.6 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.10.7-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
      "     ---------------------------------------- 0.0/199.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 199.8/199.8 kB ? eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp310-cp310-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 0.0/3.3 MB ? eta -:--:--\n",
      "     ------------------- -------------------- 1.6/3.3 MB 33.8 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 2.8/3.3 MB 29.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.3/3.3 MB 26.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.24.2)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Installing collected packages: tokenizers, typing-extensions, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.10.7 huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4 typing-extensions-4.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import os\n",
    "# import nltk\n",
    "import re\n",
    "from transformers import DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified version of Document where tokens are not included \n",
    "class Document:\n",
    "  def __init__(self, doc_no, doc_text, vector):\n",
    "    self.doc_no = doc_no\n",
    "    self.doc_text = doc_text\n",
    "    # self.tokens = tokens\n",
    "    self.vector = vector\n",
    "\n",
    "  def __str__(self):\n",
    "    # return 'Document Number: ' + self.doc_no + '\\nDocument Text: ' + self.doc_text + '\\nTokens: ' + str(self.tokens) + '\\n'\n",
    "    return 'Document Number: ' + self.doc_no + '\\nDocument Text: ' + self.doc_text  + '\\n Vectors: ' + str(self.vector) + '\\n'\n",
    "\n",
    "\n",
    "  def to_dict(self):\n",
    "    # return {'docno': self.doc_no, 'doctext': self.doc_text, 'tokens': self.tokens, 'text': ' '.join(self.tokens)}\n",
    "    return {'docno': self.doc_no, 'doctext': self.doc_text, 'vector': self.vector}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified version of preprocess where tokenizing is removed \n",
    "def preprocess(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        content = f.read()\n",
    "    documents = re.findall(r'<DOC>(.*?)</DOC>', content, re.DOTALL)\n",
    "    preprocessed_documents = []\n",
    "    for document in documents:\n",
    "        # Get the document number and text\n",
    "        raw_no = re.search(r'<DOCNO>(.*?)</DOCNO>', document, re.DOTALL)\n",
    "        doc_no = raw_no.group(1) if raw_no else ''\n",
    "        raw_text = re.search(r'<TEXT>(.*?)</TEXT>', document, re.DOTALL)\n",
    "        doc_text = raw_text.group(1) if raw_text else ''\n",
    "        doc = Document(doc_no, doc_text, None)\n",
    "        preprocessed_documents.append(doc)\n",
    "    return preprocessed_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to preprocess a directory of text files\n",
    "def preprocess_directory(directory, num_files=-1):\n",
    "  preprocessed_documents = [] \n",
    "  ctr = 0\n",
    "  for filename in os.listdir(directory):\n",
    "    print('Preprocessing file: ', filename)\n",
    "    file = os.path.join(directory, filename)\n",
    "    preprocessed_documents.extend(preprocess(file))\n",
    "    ctr += 1\n",
    "    if ctr == num_files and num_files != -1:\n",
    "      break\n",
    "  return preprocessed_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grabs the queries?\n",
    "def extract_topics(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        topic_content = f.read()\n",
    "    all_topics = []\n",
    "    topics = re.findall(r'<top>(.*?)</top>', topic_content, re.DOTALL)\n",
    "    for topic in topics:\n",
    "        raw_title = re.search(r'<title>(.*?)\\n\\n', topic, re.DOTALL)\n",
    "        title = raw_title.group(1) if raw_title else ''\n",
    "        all_topics.append(title)\n",
    "    return all_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing file:  AP880212\n",
      "Preprocessing file:  AP880213\n",
      "Preprocessing file:  AP880214\n",
      "Preprocessing file:  AP880215\n",
      "Preprocessing file:  AP880216\n",
      "Preprocessing file:  AP880217\n",
      "Preprocessing file:  AP880218\n",
      "Preprocessing file:  AP880219\n",
      "Preprocessing file:  AP880220\n",
      "Preprocessing file:  AP880221\n",
      "Preprocessing file:  AP880222\n",
      "Preprocessing file:  AP880223\n",
      "Preprocessing file:  AP880224\n",
      "Preprocessing file:  AP880225\n",
      "Preprocessing file:  AP880226\n",
      "Preprocessing file:  AP880227\n",
      "Preprocessing file:  AP880228\n",
      "Preprocessing file:  AP880229\n",
      "Preprocessing file:  AP880301\n",
      "Preprocessing file:  AP880302\n",
      "Preprocessing file:  AP880303\n",
      "Preprocessing file:  AP880304\n",
      "Preprocessing file:  AP880307\n",
      "Preprocessing file:  AP880308\n",
      "Preprocessing file:  AP880309\n",
      "Preprocessing file:  AP880310\n",
      "Preprocessing file:  AP880311\n",
      "Preprocessing file:  AP880312\n",
      "Preprocessing file:  AP880313\n",
      "Preprocessing file:  AP880314\n",
      "Preprocessing file:  AP880315\n",
      "Preprocessing file:  AP880316\n",
      "Preprocessing file:  AP880317\n",
      "Preprocessing file:  AP880318\n",
      "Preprocessing file:  AP880319\n",
      "Preprocessing file:  AP880320\n",
      "Preprocessing file:  AP880321\n",
      "Preprocessing file:  AP880322\n",
      "Preprocessing file:  AP880323\n",
      "Preprocessing file:  AP880324\n",
      "Preprocessing file:  AP880325\n",
      "Preprocessing file:  AP880326\n",
      "Preprocessing file:  AP880327\n",
      "Preprocessing file:  AP880328\n",
      "Preprocessing file:  AP880329\n",
      "Preprocessing file:  AP880330\n",
      "Preprocessing file:  AP880331\n",
      "Preprocessing file:  AP880401\n",
      "Preprocessing file:  AP880402\n",
      "Preprocessing file:  AP880403\n",
      "Preprocessing file:  AP880404\n",
      "Preprocessing file:  AP880405\n",
      "Preprocessing file:  AP880406\n",
      "Preprocessing file:  AP880407\n",
      "Preprocessing file:  AP880408\n",
      "Preprocessing file:  AP880409\n",
      "Preprocessing file:  AP880410\n",
      "Preprocessing file:  AP880411\n",
      "Preprocessing file:  AP880412\n",
      "Preprocessing file:  AP880413\n",
      "Preprocessing file:  AP880414\n",
      "Preprocessing file:  AP880415\n",
      "Preprocessing file:  AP880416\n",
      "Preprocessing file:  AP880417\n",
      "Preprocessing file:  AP880418\n",
      "Preprocessing file:  AP880419\n",
      "Preprocessing file:  AP880420\n",
      "Preprocessing file:  AP880421\n",
      "Preprocessing file:  AP880422\n",
      "Preprocessing file:  AP880423\n",
      "Preprocessing file:  AP880424\n",
      "Preprocessing file:  AP880425\n",
      "Preprocessing file:  AP880426\n",
      "Preprocessing file:  AP880427\n",
      "Preprocessing file:  AP880428\n",
      "Preprocessing file:  AP880429\n",
      "Preprocessing file:  AP880430\n",
      "Preprocessing file:  AP880501\n",
      "Preprocessing file:  AP880502\n",
      "Preprocessing file:  AP880503\n",
      "Preprocessing file:  AP880504\n",
      "Preprocessing file:  AP880505\n",
      "Preprocessing file:  AP880506\n",
      "Preprocessing file:  AP880507\n",
      "Preprocessing file:  AP880508\n",
      "Preprocessing file:  AP880509\n",
      "Preprocessing file:  AP880510\n",
      "Preprocessing file:  AP880511\n",
      "Preprocessing file:  AP880512\n",
      "Preprocessing file:  AP880513\n",
      "Preprocessing file:  AP880514\n",
      "Preprocessing file:  AP880515\n",
      "Preprocessing file:  AP880516\n",
      "Preprocessing file:  AP880517\n",
      "Preprocessing file:  AP880518\n",
      "Preprocessing file:  AP880519\n",
      "Preprocessing file:  AP880520\n",
      "Preprocessing file:  AP880521\n",
      "Preprocessing file:  AP880522\n",
      "Preprocessing file:  AP880523\n",
      "Preprocessing file:  AP880524\n",
      "Preprocessing file:  AP880525\n",
      "Preprocessing file:  AP880526\n",
      "Preprocessing file:  AP880527\n",
      "Preprocessing file:  AP880528\n",
      "Preprocessing file:  AP880529\n",
      "Preprocessing file:  AP880530\n",
      "Preprocessing file:  AP880531\n",
      "Preprocessing file:  AP880601\n",
      "Preprocessing file:  AP880602\n",
      "Preprocessing file:  AP880603\n",
      "Preprocessing file:  AP880604\n",
      "Preprocessing file:  AP880605\n",
      "Preprocessing file:  AP880606\n",
      "Preprocessing file:  AP880607\n",
      "Preprocessing file:  AP880608\n",
      "Preprocessing file:  AP880609\n",
      "Preprocessing file:  AP880610\n",
      "Preprocessing file:  AP880611\n",
      "Preprocessing file:  AP880612\n",
      "Preprocessing file:  AP880613\n",
      "Preprocessing file:  AP880614\n",
      "Preprocessing file:  AP880615\n",
      "Preprocessing file:  AP880616\n",
      "Preprocessing file:  AP880617\n",
      "Preprocessing file:  AP880618\n",
      "Preprocessing file:  AP880619\n",
      "Preprocessing file:  AP880620\n",
      "Preprocessing file:  AP880621\n",
      "Preprocessing file:  AP880622\n",
      "Preprocessing file:  AP880623\n",
      "Preprocessing file:  AP880624\n",
      "Preprocessing file:  AP880625\n",
      "Preprocessing file:  AP880626\n",
      "Preprocessing file:  AP880627\n",
      "Preprocessing file:  AP880628\n",
      "Preprocessing file:  AP880629\n",
      "Preprocessing file:  AP880630\n",
      "Preprocessing file:  AP880701\n",
      "Preprocessing file:  AP880702\n",
      "Preprocessing file:  AP880703\n",
      "Preprocessing file:  AP880704\n",
      "Preprocessing file:  AP880705\n",
      "Preprocessing file:  AP880706\n",
      "Preprocessing file:  AP880707\n",
      "Preprocessing file:  AP880708\n",
      "Preprocessing file:  AP880709\n",
      "Preprocessing file:  AP880710\n",
      "Preprocessing file:  AP880711\n",
      "Preprocessing file:  AP880712\n",
      "Preprocessing file:  AP880713\n",
      "Preprocessing file:  AP880714\n",
      "Preprocessing file:  AP880715\n",
      "Preprocessing file:  AP880716\n",
      "Preprocessing file:  AP880717\n",
      "Preprocessing file:  AP880718\n",
      "Preprocessing file:  AP880719\n",
      "Preprocessing file:  AP880720\n",
      "Preprocessing file:  AP880721\n",
      "Preprocessing file:  AP880722\n",
      "Preprocessing file:  AP880723\n",
      "Preprocessing file:  AP880724\n",
      "Preprocessing file:  AP880725\n",
      "Preprocessing file:  AP880726\n",
      "Preprocessing file:  AP880727\n",
      "Preprocessing file:  AP880728\n",
      "Preprocessing file:  AP880729\n",
      "Preprocessing file:  AP880730\n",
      "Preprocessing file:  AP880731\n",
      "Preprocessing file:  AP880801\n",
      "Preprocessing file:  AP880802\n",
      "Preprocessing file:  AP880803\n",
      "Preprocessing file:  AP880804\n",
      "Preprocessing file:  AP880805\n",
      "Preprocessing file:  AP880806\n",
      "Preprocessing file:  AP880807\n",
      "Preprocessing file:  AP880808\n",
      "Preprocessing file:  AP880809\n",
      "Preprocessing file:  AP880810\n",
      "Preprocessing file:  AP880811\n",
      "Preprocessing file:  AP880812\n",
      "Preprocessing file:  AP880813\n",
      "Preprocessing file:  AP880814\n",
      "Preprocessing file:  AP880815\n",
      "Preprocessing file:  AP880816\n",
      "Preprocessing file:  AP880817\n",
      "Preprocessing file:  AP880818\n",
      "Preprocessing file:  AP880819\n",
      "Preprocessing file:  AP880820\n",
      "Preprocessing file:  AP880821\n",
      "Preprocessing file:  AP880822\n",
      "Preprocessing file:  AP880823\n",
      "Preprocessing file:  AP880824\n",
      "Preprocessing file:  AP880825\n",
      "Preprocessing file:  AP880826\n",
      "Preprocessing file:  AP880827\n",
      "Preprocessing file:  AP880828\n",
      "Preprocessing file:  AP880829\n",
      "Preprocessing file:  AP880830\n",
      "Preprocessing file:  AP880831\n",
      "Preprocessing file:  AP880901\n",
      "Preprocessing file:  AP880902\n",
      "Preprocessing file:  AP880903\n",
      "Preprocessing file:  AP880904\n",
      "Preprocessing file:  AP880905\n",
      "Preprocessing file:  AP880906\n",
      "Preprocessing file:  AP880907\n",
      "Preprocessing file:  AP880908\n",
      "Preprocessing file:  AP880909\n",
      "Preprocessing file:  AP880910\n",
      "Preprocessing file:  AP880911\n",
      "Preprocessing file:  AP880912\n",
      "Preprocessing file:  AP880913\n",
      "Preprocessing file:  AP880914\n",
      "Preprocessing file:  AP880915\n",
      "Preprocessing file:  AP880916\n",
      "Preprocessing file:  AP880917\n",
      "Preprocessing file:  AP880918\n",
      "Preprocessing file:  AP880919\n",
      "Preprocessing file:  AP880920\n",
      "Preprocessing file:  AP880921\n",
      "Preprocessing file:  AP880922\n",
      "Preprocessing file:  AP880923\n",
      "Preprocessing file:  AP880924\n",
      "Preprocessing file:  AP880925\n",
      "Preprocessing file:  AP880926\n",
      "Preprocessing file:  AP880927\n",
      "Preprocessing file:  AP880928\n",
      "Preprocessing file:  AP880929\n",
      "Preprocessing file:  AP880930\n",
      "Preprocessing file:  AP881001\n",
      "Preprocessing file:  AP881002\n",
      "Preprocessing file:  AP881003\n",
      "Preprocessing file:  AP881004\n",
      "Preprocessing file:  AP881005\n",
      "Preprocessing file:  AP881006\n",
      "Preprocessing file:  AP881007\n",
      "Preprocessing file:  AP881008\n",
      "Preprocessing file:  AP881009\n",
      "Preprocessing file:  AP881010\n",
      "Preprocessing file:  AP881011\n",
      "Preprocessing file:  AP881012\n",
      "Preprocessing file:  AP881013\n",
      "Preprocessing file:  AP881014\n",
      "Preprocessing file:  AP881015\n",
      "Preprocessing file:  AP881016\n",
      "Preprocessing file:  AP881017\n",
      "Preprocessing file:  AP881018\n",
      "Preprocessing file:  AP881019\n",
      "Preprocessing file:  AP881020\n",
      "Preprocessing file:  AP881021\n",
      "Preprocessing file:  AP881022\n",
      "Preprocessing file:  AP881023\n",
      "Preprocessing file:  AP881024\n",
      "Preprocessing file:  AP881025\n",
      "Preprocessing file:  AP881026\n",
      "Preprocessing file:  AP881027\n",
      "Preprocessing file:  AP881028\n",
      "Preprocessing file:  AP881029\n",
      "Preprocessing file:  AP881030\n",
      "Preprocessing file:  AP881031\n",
      "Preprocessing file:  AP881101\n",
      "Preprocessing file:  AP881102\n",
      "Preprocessing file:  AP881103\n",
      "Preprocessing file:  AP881104\n",
      "Preprocessing file:  AP881105\n",
      "Preprocessing file:  AP881106\n",
      "Preprocessing file:  AP881107\n",
      "Preprocessing file:  AP881108\n",
      "Preprocessing file:  AP881109\n",
      "Preprocessing file:  AP881110\n",
      "Preprocessing file:  AP881111\n",
      "Preprocessing file:  AP881112\n",
      "Preprocessing file:  AP881113\n",
      "Preprocessing file:  AP881114\n",
      "Preprocessing file:  AP881115\n",
      "Preprocessing file:  AP881116\n",
      "Preprocessing file:  AP881117\n",
      "Preprocessing file:  AP881118\n",
      "Preprocessing file:  AP881119\n",
      "Preprocessing file:  AP881120\n",
      "Preprocessing file:  AP881121\n",
      "Preprocessing file:  AP881122\n",
      "Preprocessing file:  AP881123\n",
      "Preprocessing file:  AP881124\n",
      "Preprocessing file:  AP881125\n",
      "Preprocessing file:  AP881126\n",
      "Preprocessing file:  AP881127\n",
      "Preprocessing file:  AP881128\n",
      "Preprocessing file:  AP881129\n",
      "Preprocessing file:  AP881130\n",
      "Preprocessing file:  AP881201\n",
      "Preprocessing file:  AP881202\n",
      "Preprocessing file:  AP881203\n",
      "Preprocessing file:  AP881204\n",
      "Preprocessing file:  AP881205\n",
      "Preprocessing file:  AP881206\n",
      "Preprocessing file:  AP881207\n",
      "Preprocessing file:  AP881208\n",
      "Preprocessing file:  AP881209\n",
      "Preprocessing file:  AP881210\n",
      "Preprocessing file:  AP881211\n",
      "Preprocessing file:  AP881212\n",
      "Preprocessing file:  AP881213\n",
      "Preprocessing file:  AP881214\n",
      "Preprocessing file:  AP881215\n",
      "Preprocessing file:  AP881216\n",
      "Preprocessing file:  AP881217\n",
      "Preprocessing file:  AP881218\n",
      "Preprocessing file:  AP881219\n",
      "Preprocessing file:  AP881220\n",
      "Preprocessing file:  AP881221\n",
      "Preprocessing file:  AP881222\n",
      "Preprocessing file:  AP881223\n",
      "Preprocessing file:  AP881224\n",
      "Preprocessing file:  AP881225\n",
      "Preprocessing file:  AP881226\n",
      "Preprocessing file:  AP881227\n",
      "Preprocessing file:  AP881228\n",
      "Preprocessing file:  AP881229\n",
      "Preprocessing file:  AP881230\n",
      "Preprocessing file:  AP881231\n"
     ]
    }
   ],
   "source": [
    "extracted_documents = preprocess_directory('AP_collection\\coll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AP880212-0171 \n",
      "\n",
      "\n",
      "   New York investor Donald Trump may\n",
      "seek up to 24.9 percent of MCA Inc., the parent of Universal\n",
      "Studios, the entertainment conglomerate said Friday.\n",
      "   It has been speculated for more than a year that MCA would be a\n",
      "takeover target, but until now no suitor has emerged.\n",
      "   Some analysts have long contended the company's stock was\n",
      "undervalued. But it was believed a hostile takeover would be\n",
      "difficult because MCA is ruled with an iron hand by Lew Wasserman,\n",
      "the last of the old-line movie moguls.\n",
      "   Wasserman, 74, has been with MCA and its forerunner, Music Corp.\n",
      "of America, since 1936.\n",
      "   In a brief announcement, MCA said it had been notified by Trump\n",
      "that he owns 375,000 of the company's shares and may seek to\n",
      "acquire 24.9 percent.\n",
      "   MCA has 77.1 million shares outstanding.\n",
      "   MCA's announcement came after the stock market closed, but the\n",
      "company's stock already had jumped by $5.25 per share to $45 on\n",
      "rumors that a takeover bid was in the offing.\n",
      "   Like most other companies, MCA's shares took a beating in the\n",
      "stock market crash and never fully recovered. In the past year,\n",
      "their highest price was $64.50.\n",
      "   Trump spokeswoman Norma Foerderer in New York said she had no\n",
      "comment.\n",
      "   MCA takeover speculation peaked in mid-1987 when Wasserman was\n",
      "hospitalized for a prolonged period after what was to have been\n",
      "routine surgery to remove a polyp from his colon.\n",
      "   However, Wasserman did return to the helm of the entertainment\n",
      "giant after five weeks, reportedly with his corporate power\n",
      "undiminished.\n",
      "   To dissaude suitors, MCA last July adopted a ``poison-pill''\n",
      "permitting stockholders to buy new shares at half price if a\n",
      "hostile bidder acquired more than 20 percent of MCA or made an\n",
      "unsolicited tender offer for more than 30 percent.\n",
      "   Wasserman's control comes more from the respect he commands than\n",
      "from the stock he controls.\n",
      "   Wasserman owns 6.9 percent of MCA's stock and controls another\n",
      "8.9 percent through a series of trusts, including those of the\n",
      "family of MCA founder Jules Stein.\n",
      "   From its beginning as a Hollywood talent-booking agency, MCA has\n",
      "grown into a powerhouse in producing movies, television\n",
      "programming, records and toys.\n",
      "   It operates a successful backlot tour of Universal Studios here,\n",
      "is building one in Florida and has agreed to build one in Japan. In\n",
      "all three locations, it would be competing with theme parks by its\n",
      "arch-rival Walt Disney Co.\n",
      "   MCA also is involved in book publishing, retail and mail-order\n",
      "businesses.\n",
      "   In 1987, MCA earned $137.9 million, or $1.97 per share, a\n",
      "decrease of 9 percent from a year earlier when it netted $150.9\n",
      "million, or $1.97 per share.\n",
      "   The decline would have been even more dramatic except that the\n",
      "1986 results already were depressed by a $50 million writeoff to\n",
      "cover bills it was unlikely to collect from independent television\n",
      "stations that had used MCA programs.\n",
      "   Trump, who made his fortune in New York real estate, is building\n",
      "a casino empire with two hotel-gaming houses already in Atlantic\n",
      "City, N.J., and a permit pending for a third one.\n",
      "   Trump also is seeking to gain total control of Atlantic\n",
      "City-based Resorts International Inc. He already owns 90 percent of\n",
      "the company's voting power.\n",
      "   In addition, Trump in the past has acquired stakes in takeover\n",
      "targets and later sold them for a handsome profit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(extracted_documents[0].doc_no + \"\\n\")\n",
    "print(extracted_documents[0].doc_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coping with overcrowded prisons',\n",
       " 'Accusations of Cheating by Contractors on U.S. Defense Projects',\n",
       " 'Insurance Coverage which pays for Long Term Care',\n",
       " 'Oil Spills',\n",
       " 'Right Wing Christian Fundamentalism in U.S. ',\n",
       " 'Efforts to enact Gun Control Legislation ',\n",
       " 'Causes and treatments of multiple sclerosis (MS) ',\n",
       " 'Term limitations for members of the U.S. Congress ',\n",
       " 'Electric Car Development ',\n",
       " 'Vitamins - The Cure for or Cause of\\nHuman Ailments ',\n",
       " 'Acid Rain  ',\n",
       " 'Automobile Recalls ',\n",
       " 'Vietnam Veterans and Agent Orange ',\n",
       " 'Generic Drugs - Illegal Activities by Manufacturers ',\n",
       " 'Tobacco company advertising and the young ',\n",
       " 'Standardized testing and cultural bias ',\n",
       " ' Topic: Regulation of the showing of violence and explicit\\nsex in motion picture theaters, on television, and on video \\ncassettes. ',\n",
       " 'Financing AMTRAK ',\n",
       " 'Cost of Garbage/Trash Removal ',\n",
       " 'The Consequences of Implantation of Silicone Gel \\nBreast Devices ',\n",
       " \"Use of Mutual Funds in an Individual's    \\nRetirement Strategy \",\n",
       " 'The Effectiveness of Medical Products and\\nRelated Programs Utilized in the Cessation of Smoking. ',\n",
       " 'Smoking Bans ',\n",
       " 'Hazardous Waste Cleanup ',\n",
       " 'NRA Prevention of Gun Control Legislation ',\n",
       " 'Real-life private investigators',\n",
       " 'English as the Official Language in U.S. ',\n",
       " 'Dog Maulings ',\n",
       " 'U. S. Restaurants in Foreign Lands ',\n",
       " 'Ineffectiveness of U.S. Embargoes/Sanctions ',\n",
       " 'Abuse of the Elderly by Family Members, and Medical and\\nNonmedical Personnel, and Initiatives Being Taken to Minimize This \\nMistreatment ',\n",
       " 'Commercial Overfishing Creates Food Fish Deficit  ',\n",
       " 'Asbestos Related Lawsuits ',\n",
       " 'Corporate Pension Plans/Funds ',\n",
       " 'Reform of the U.S. Welfare System ',\n",
       " ' Topic:  Difference of Learning Levels Among Inner\\nCity and More Suburban School Students ',\n",
       " 'Signs of the Demise of Independent Publishing ',\n",
       " 'Beachfront Erosion ',\n",
       " 'Real Motives for Murder ',\n",
       " 'Instances of Fraud Involving the Use of a Computer',\n",
       " 'Efforts to Improve U.S. Schooling ',\n",
       " 'Oil Spill Cleanup ',\n",
       " 'Toys R Dangerous ',\n",
       " 'The Amount of Money Earned by Writers ',\n",
       " 'Stock Market Perturbations Attributable to\\nComputer Initiated Trading',\n",
       " 'School Choice Voucher System and its effects\\nupon the entire U.S. educational program ',\n",
       " 'Reform of the jurisprudence system\\nto stop juries from granting unreasonable monetary\\nawards ',\n",
       " ' Gene Therapy and Its Benefits to \\nHumankind ',\n",
       " 'Legality of Medically Assisted Suicides ',\n",
       " 'Impact of foreign textile imports on U.S.\\ntextile industry']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = extract_topics(\"topics1-50.txt\")\n",
    "topics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistillBERT Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
